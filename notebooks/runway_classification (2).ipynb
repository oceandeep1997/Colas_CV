{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a46420-993e-4fbc-8262-b8771d76baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bf288-6983-497d-957e-2e062701d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def oversampler(X, y):    \n",
    "    X = list(X)\n",
    "    counter = int(y.mean() * len(y))\n",
    "    while counter / len(y) < 0.5:\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:\n",
    "                X.append(X[i])\n",
    "                y = np.append(y, y[i])\n",
    "                counter += 1\n",
    "            if counter / len(y) >= 0.5:\n",
    "                break\n",
    "    X = np.array(X)\n",
    "    return X, y\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32154311-ea5b-4e2b-89fe-cb1c973e0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"hfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57720169-2605-4698-a7a0-4b84f3bcf33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(dataset_path + \"labels_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf208fc-a93d-491b-bed5-3692c65b7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d99541-a052-4b31-97e4-fc7c23360ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train_labels.shape[0])):\n",
    "    img = load_img(dataset_path + \"train/\" + train_labels[\"filename\"][i], target_size=(224,224,3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde9435-27e3-424a-b45a-3574297feb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b1931-0a64-4b57-ae8b-7f41f7cde61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train_labels.drop([\"filename\"], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844a6fb-0ac7-4fa3-8512-80a5badce494",
   "metadata": {},
   "source": [
    "### One Model for Each Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7c556-ca05-43cd-a97d-85d6b3cdb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5fb98-3103-4848-8e27-ea870669fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy',metrics = ['acc', AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d72148-af66-477d-86b2-85a37506fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fissure = np.array(train_labels[\"FISSURE\"])\n",
    "y_reparation = np.array(train_labels[\"REPARATION\"])\n",
    "y_longi = np.array(train_labels[\"FISSURE LONGITUDINALE\"])\n",
    "y_faience = np.array(train_labels[\"FAÏENCAGE\"])\n",
    "y_med = np.array(train_labels[\"MISE EN DALLE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e8e19-f62d-4796-b362-ed7ae75a9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_fissure.mean())\n",
    "print(y_reparation.mean())\n",
    "print(y_longi.mean())\n",
    "print(y_faience.mean())\n",
    "print(y_med.mean())\n",
    "print(len(y_fissure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442575a-2927-40a0-a5b0-6d3a03f4c50b",
   "metadata": {},
   "source": [
    "#### FISSURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e975f-57b4-460b-b22d-c2e3d1828ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fissure_train, X_fissure_test, y_fissure_train, y_fissure_test = train_test_split(X, y_fissure, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c72f4e-6639-4504-968a-3fa25c58d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fissure_train, y_fissure_train = oversampler(X_fissure_train, y_fissure_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89db544-6780-48e5-8275-3dcc92f15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_fissure_train))\n",
    "print(y_fissure_train.mean())\n",
    "print(X_fissure_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56547b-8ce2-490b-bbf5-23d661f43d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg1hist = model.fit(X_fissure_train, y_fissure_train, validation_data = (X_fissure_test, y_fissure_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaed01d-7b37-4770-bcad-5d89cfcc14c7",
   "metadata": {},
   "source": [
    "#### REPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db35aa-e609-42f8-b2e3-b97cd196d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reparation_train, X_reparation_test, y_reparation_train, y_reparation_test = train_test_split(X, y_reparation, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7691dd8-9a26-4441-94b6-66ccdabf0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reparation_train, y_reparation_train = oversampler(X_reparation_train, y_reparation_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e795f-aac4-4195-89c7-b0d2a71718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_reparation_train))\n",
    "print(y_reparation_train.mean())\n",
    "print(X_reparation_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c00284-6de7-424e-90e1-18ea05dab234",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg2hist = model.fit(X_reparation_train, y_reparation_train, validation_data = (X_reparation_test, y_reparation_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e0c79-1db8-4105-8570-72c53d6f33a6",
   "metadata": {},
   "source": [
    "#### FISSURE LONGITUDINALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980d4cc-5fba-410d-add1-c96d06a30eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_longi_train, X_longi_test, y_longi_train, y_longi_test = train_test_split(X, y_longi, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf66f97-c418-4880-9ded-1fb50919996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_longi_train, y_longi_train = oversampler(X_longi_train, y_longi_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63842fd2-dfe7-459b-9c7d-c4a49bc8436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_longi_train))\n",
    "print(y_longi_train.mean())\n",
    "print(X_longi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d989fe7-eaaa-45fa-b0b0-b788594296e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg3hist = model.fit(X_longi_train, y_longi_train, validation_data = (X_longi_test, y_longi_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace0257-0bf9-4ea9-bb72-e70aaaa50ff2",
   "metadata": {},
   "source": [
    "#### FAIENÇAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd61d6e-8081-4184-9a79-0606df639502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_faience_train, X_faience_test, y_faience_train, y_faience_test = train_test_split(X, y_faience, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd98a8-4d08-455a-9b68-d34f418e37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_faience_train, y_faience_train = oversampler(X_faience_train, y_faience_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f0e20-c4d8-441e-a789-9d6cbac24fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_faience_train))\n",
    "print(y_faience_train.mean())\n",
    "print(X_faience_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf7d8e-3fa6-4900-879b-72a7bb572a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg4hist = model.fit(X_faience_train, y_faience_train, validation_data = (X_faience_test, y_faience_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aff3fc-cc89-4666-a125-e2a0a0e8937a",
   "metadata": {},
   "source": [
    "#### MISE EN DALLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9462a17-6907-4563-88ac-5eafde3145fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_med_train, X_med_test, y_med_train, y_med_test = train_test_split(X, y_med, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026b9db-bcef-4dab-9ead-ab94aace085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_med_train, y_med_train = oversampler(X_med_train, y_med_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794f818-7e02-4dff-9ecc-b1b2c10db48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_med_train))\n",
    "print(y_med_train.mean())\n",
    "print(X_med_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9304a-fb9b-4f96-994c-2badcd5c7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg5hist = model.fit(X_med_train, y_med_train, validation_data = (X_med_test, y_med_test), epochs = 20, batch_size = 32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
