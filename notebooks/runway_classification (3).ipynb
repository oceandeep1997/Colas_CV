{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a46420-993e-4fbc-8262-b8771d76baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rand\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90471d31-325b-4d78-8c6c-620d60145f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bf288-6983-497d-957e-2e062701d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def oversampler(X, y):    \n",
    "    X = list(X)\n",
    "    counter = int(y.mean() * len(y))\n",
    "    angles = [90, 180, 270]\n",
    "    i = 0\n",
    "    angle = 90\n",
    "    while counter / len(y) < 0.5:\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:\n",
    "                # get dims, find center\n",
    "                image = X[i]\n",
    "                (h, w) = image.shape[:2]\n",
    "                (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "                # grab the rotation matrix (applying the negative of the\n",
    "                # angle to rotate clockwise), then grab the sine and cosine\n",
    "                # (i.e., the rotation components of the matrix)\n",
    "                M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "                cos = np.abs(M[0, 0])\n",
    "                sin = np.abs(M[0, 1])\n",
    "\n",
    "                # compute the new bounding dimensions of the image\n",
    "                nW = int((h * sin) + (w * cos))\n",
    "                nH = int((h * cos) + (w * sin))\n",
    "\n",
    "                # adjust the rotation matrix to take into account translation\n",
    "                M[0, 2] += (nW / 2) - cX\n",
    "                M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "                # perform the actual rotation and return the image\n",
    "                image = cv2.warpAffine(image, M, (nW, nH), False)\n",
    "\n",
    "                X.append(image)\n",
    "                y = np.append(y, y[i])\n",
    "                counter += 1\n",
    "            if counter / len(y) >= 0.5:\n",
    "                break\n",
    "\n",
    "        i += 1\n",
    "        angle = angles[i%3]\n",
    "    X = np.array(X)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32154311-ea5b-4e2b-89fe-cb1c973e0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"hfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57720169-2605-4698-a7a0-4b84f3bcf33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(dataset_path + \"labels_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf208fc-a93d-491b-bed5-3692c65b7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d99541-a052-4b31-97e4-fc7c23360ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train_labels.shape[0])):\n",
    "    img = load_img(dataset_path + \"train/\" + train_labels[\"filename\"][i], target_size=(224,224,3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c25d56-ff36-4a9a-8fd8-90be9aa79ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[145])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e664c9b-f49d-4d81-ab34-0548040ee424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(dataset_path + \"template_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad4142-80e5-43aa-83cd-8ae4795a75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba71c0-9a33-4ef9-bea7-030b303cfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for i in tqdm(range(test_labels.shape[0])):\n",
    "    img = load_img(dataset_path + \"test/\" + test_labels[\"filename\"][i], target_size=(224,224,3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    test_images.append(img)\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844a6fb-0ac7-4fa3-8512-80a5badce494",
   "metadata": {},
   "source": [
    "### One Model for Each Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7c556-ca05-43cd-a97d-85d6b3cdb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "include_top = False, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5fb98-3103-4848-8e27-ea870669fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy',metrics = ['acc', AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5cf03-13fc-475d-8ac2-31dd93f10717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d72148-af66-477d-86b2-85a37506fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fissure = np.array(train_labels[\"FISSURE\"])\n",
    "y_reparation = np.array(train_labels[\"REPARATION\"])\n",
    "y_longi = np.array(train_labels[\"FISSURE LONGITUDINALE\"])\n",
    "y_faience = np.array(train_labels[\"FA√èENCAGE\"])\n",
    "y_med = np.array(train_labels[\"MISE EN DALLE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e8e19-f62d-4796-b362-ed7ae75a9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_fissure.mean())\n",
    "print(y_reparation.mean())\n",
    "print(y_longi.mean())\n",
    "print(y_faience.mean())\n",
    "print(y_med.mean())\n",
    "print(len(y_fissure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442575a-2927-40a0-a5b0-6d3a03f4c50b",
   "metadata": {},
   "source": [
    "#### FISSURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e975f-57b4-460b-b22d-c2e3d1828ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fissure_train, X_fissure_test, y_fissure_train, y_fissure_test = train_test_split(X, y_fissure, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c72f4e-6639-4504-968a-3fa25c58d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fissure_train, y_fissure_train = oversampler(X_fissure_train, y_fissure_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89db544-6780-48e5-8275-3dcc92f15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_fissure_train))\n",
    "print(y_fissure_train.mean())\n",
    "print(X_fissure_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56547b-8ce2-490b-bbf5-23d661f43d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg1hist = model.fit(X_fissure_train, y_fissure_train, validation_data = (X_fissure_test, y_fissure_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a76ad-8f1c-47f7-b2bc-753b056b7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "fissure_pred = model.predict(test_images)\n",
    "fissure_pred.reshape(200)\n",
    "fissure_pred_1 = np.round(fissure_pred)\n",
    "prior_adjusted_fissure_pred = np.round(fissure_pred * y_fissure.mean() / fissure_pred_1.mean())\n",
    "prior_adjusted_fissure_pred = np.array([min(int(i), 1) for i in prior_adjusted_fissure_pred])\n",
    "print(prior_adjusted_fissure_pred.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaed01d-7b37-4770-bcad-5d89cfcc14c7",
   "metadata": {},
   "source": [
    "#### REPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db35aa-e609-42f8-b2e3-b97cd196d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reparation_train, X_reparation_test, y_reparation_train, y_reparation_test = train_test_split(X, y_reparation, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7691dd8-9a26-4441-94b6-66ccdabf0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reparation_train, y_reparation_train = oversampler(X_reparation_train, y_reparation_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e795f-aac4-4195-89c7-b0d2a71718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_reparation_train))\n",
    "print(y_reparation_train.mean())\n",
    "print(X_reparation_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c00284-6de7-424e-90e1-18ea05dab234",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg2hist = model.fit(X_reparation_train, y_reparation_train, validation_data = (X_reparation_test, y_reparation_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41adb54d-70cf-4bda-9276-28fda6f2c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reparation_pred = model.predict(test_images)\n",
    "reparation_pred.reshape(200)\n",
    "reparation_pred_1 = np.round(reparation_pred)\n",
    "print(reparation_pred_1.mean())\n",
    "print(y_reparation.mean() / reparation_pred_1.mean())\n",
    "prior_adjusted_reparation_pred = np.round(reparation_pred * y_reparation.mean() / reparation_pred_1.mean())\n",
    "prior_adjusted_reparation_pred = np.array([min(int(i), 1) for i in prior_adjusted_reparation_pred])\n",
    "print(prior_adjusted_reparation_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e0c79-1db8-4105-8570-72c53d6f33a6",
   "metadata": {},
   "source": [
    "#### FISSURE LONGITUDINALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980d4cc-5fba-410d-add1-c96d06a30eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_longi_train, X_longi_test, y_longi_train, y_longi_test = train_test_split(X, y_longi, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf66f97-c418-4880-9ded-1fb50919996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_longi_train, y_longi_train = oversampler(X_longi_train, y_longi_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63842fd2-dfe7-459b-9c7d-c4a49bc8436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_longi_train))\n",
    "print(y_longi_train.mean())\n",
    "print(X_longi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d989fe7-eaaa-45fa-b0b0-b788594296e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg3hist = model.fit(X_longi_train, y_longi_train, validation_data = (X_longi_test, y_longi_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b7b32-eeca-4420-a003-e3be2dd34823",
   "metadata": {},
   "outputs": [],
   "source": [
    "longi_pred = model.predict(test_images)\n",
    "longi_pred.reshape(200)\n",
    "longi_pred_1 = np.round(longi_pred)\n",
    "print(longi_pred_1.mean())\n",
    "print(y_longi.mean() / longi_pred_1.mean())\n",
    "prior_adjusted_longi_pred = np.round(longi_pred * y_longi.mean() / longi_pred_1.mean())\n",
    "prior_adjusted_longi_pred = np.array([min(int(i), 1) for i in prior_adjusted_longi_pred])\n",
    "print(prior_adjusted_longi_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace0257-0bf9-4ea9-bb72-e70aaaa50ff2",
   "metadata": {},
   "source": [
    "#### FAIEN√áAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd61d6e-8081-4184-9a79-0606df639502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_faience_train, X_faience_test, y_faience_train, y_faience_test = train_test_split(X, y_faience, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd98a8-4d08-455a-9b68-d34f418e37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_faience_train, y_faience_train = oversampler(X_faience_train, y_faience_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f0e20-c4d8-441e-a789-9d6cbac24fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_faience_train))\n",
    "print(y_faience_train.mean())\n",
    "print(X_faience_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf7d8e-3fa6-4900-879b-72a7bb572a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg4hist = model.fit(X_faience_train, y_faience_train, validation_data = (X_faience_test, y_faience_test), epochs = 10, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc091e09-521e-4771-9f83-5aad64d835ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "faience_pred = model.predict(test_images)\n",
    "faience_pred.reshape(200)\n",
    "faience_pred_1 = np.round(faience_pred)\n",
    "print(faience_pred_1.mean())\n",
    "prior_adjusted_faience_pred = np.round(faience_pred * y_faience.mean() / faience_pred_1.mean())\n",
    "prior_adjusted_faience_pred = np.array([min(int(i), 1) for i in prior_adjusted_faience_pred])\n",
    "print(prior_adjusted_faience_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aff3fc-cc89-4666-a125-e2a0a0e8937a",
   "metadata": {},
   "source": [
    "#### MISE EN DALLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9462a17-6907-4563-88ac-5eafde3145fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_med_train, X_med_test, y_med_train, y_med_test = train_test_split(X, y_med, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026b9db-bcef-4dab-9ead-ab94aace085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_med_train, y_med_train = oversampler(X_med_train, y_med_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2794f818-7e02-4dff-9ecc-b1b2c10db48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_med_train))\n",
    "print(y_med_train.mean())\n",
    "print(X_med_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9304a-fb9b-4f96-994c-2badcd5c7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg5hist = model.fit(X_med_train, y_med_train, validation_data = (X_med_test, y_med_test), epochs = 20, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c5a51-2e11-4549-b8ea-148687da5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_pred = model.predict(test_images)\n",
    "med_pred.reshape(200)\n",
    "med_pred_1 = np.round(med_pred)\n",
    "print(med_pred_1.mean())\n",
    "print(y_med.mean() / med_pred_1.mean())\n",
    "prior_adjusted_med_pred = np.round(med_pred * y_med.mean() / med_pred_1.mean())\n",
    "prior_adjusted_med_pred = np.array([min(int(i), 1) for i in prior_adjusted_med_pred])\n",
    "print(prior_adjusted_med_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5525e4e-0a0f-4a00-8fa9-706dea7713c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[\"FISSURE\"] = prior_adjusted_fissure_pred\n",
    "test_labels[\"REPARATION\"] = prior_adjusted_reparation_pred\n",
    "test_labels[\"FISSURE LONGITUDINALE\"] = prior_adjusted_longi_pred\n",
    "test_labels[\"FA√èENCAGE\"] = prior_adjusted_faience_pred\n",
    "test_labels[\"MISE EN DALLE\"] = prior_adjusted_med_pred\n",
    "\n",
    "test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478d1e7-1b6b-497c-b9a6-e3a932264928",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
